model = "gpt-5.2-codex"
model_reasoning_effort = "high"

# Leave room for native compaction near the 272–273k context window.
# Formula: 273000 - (tool_output_token_limit + 15000)
# With tool_output_token_limit=25000 ⇒ 273000 - (25000 + 15000) = 233000
tool_output_token_limit = 25000
model_auto_compact_token_limit = 233000

approval_policy = "on-failure"
sandbox_mode = "workspace-write"

[sandbox_workspace_write]
network_access = true

[shell_environment_policy]
inherit = "all"
ignore_default_excludes = true
experimental_use_profile = true

[tui]
notifications = true

[features] 
parallel = true
unified_exec = true
web_search_request = true
view_image_tool = true
skills = true
apply_patch_freeform = true
undo = true
shell_snapshot = true

[projects."/Users/segersniels/projects"]
trust_level = "trusted"

[projects."/Users/segersniels/personal"]
trust_level = "trusted"

[mcp_servers.notion]
command = "npx"
args = ["-y", "mcp-remote@latest", "https://mcp.notion.com/mcp"]
